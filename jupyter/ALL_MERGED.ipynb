{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Adam wykrywanie tekstu za pomocą canny.\n",
    "Do następnego punktu potrzebny mi jest:\n",
    "    - img: Na wejście dostaje obraz binarny, gdzie wykryte tekst jest wskazywany przez 1, a reszta to 0.\n",
    "    - img_org: Oryginalny niezmieniony obraz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wykrywanie fragmentu obrazu z tekstem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "from skimage import exposure\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_centroids(data, quantile_height=0.9, quantile_width=0.9):\n",
    "    Q1 = np.quantile(data[:, 0], 1-quantile_height)\n",
    "    Q3 = np.quantile(data[:, 0], quantile_height)\n",
    "    IQR = Q3 - Q1\n",
    "    data = np.array([el for el in data if el[0] > Q1 and el[0] < Q3])\n",
    "\n",
    "    Q1 = np.quantile(data[:, 1], 1-quantile_width)\n",
    "    Q3 = np.quantile(data[:, 1], quantile_width)\n",
    "    IQR = Q3 - Q1\n",
    "    data = np.array([el for el in data if el[1] > Q1 and el[1] < Q3])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def remove_background_on_left_side(img):\n",
    "    img_org = img.copy()\n",
    "    \n",
    "    ############ Jeżeli zwracać obraz w skali szarości, bez rozciągania histogramu to użyć tego ############\n",
    "    ############ ,a w głównej funkcji usunąć ############\n",
    "#     p2, p98 = np.percentile(img, (2, 98))\n",
    "#     img = exposure.rescale_intensity(img_slice, in_range=(p2, p98))\n",
    "    ###########################################################################################\n",
    "    \n",
    "    # Sprawdzamy średnią jasność obrazu. Następnie bierzemy po kolei grupy kolumn (skłądające się z step kolumn).\n",
    "    # Jeżeli jasność w grupie jest mniejsza niż (średnia w obrazie - bias) to zastępujemy wartością średnią.\n",
    "    mean_value_in_img = np.mean(img) \n",
    "    step = 10\n",
    "    bias = 0.2 # 0.07 bez roziągania histogramu\n",
    "    was_action = True \n",
    "    for el in range(0, len(img.T), step):\n",
    "        if np.mean(img[:,el:el+step]) < mean_value_in_img-bias:\n",
    "#             img[:,el:el+step] = mean_value_in_img\n",
    "            img_org = img_org[:,el+step:]\n",
    "            was_action = True\n",
    "        else:\n",
    "            was_action = False\n",
    "        \n",
    "        if not was_action:\n",
    "#             img[:,el:el+step] = mean_value_in_img\n",
    "            img_org = img_org[:,el+int(step/2):]\n",
    "            break\n",
    "            \n",
    "    return img_org\n",
    "\n",
    "def remove_background(img):\n",
    "     # usuwa z lewej\n",
    "    img = remove_background_on_left_side(img)\n",
    "    \n",
    "     # usuwa z prawej\n",
    "    img = transform.rotate(img, 180)\n",
    "    img = remove_background_on_left_side(img)\n",
    "    \n",
    "    # usuwa z dołu\n",
    "    img = img.T\n",
    "    img = remove_background_on_left_side(img)\n",
    "    \n",
    "    # usuwa z góry\n",
    "    img = transform.rotate(img, 180)\n",
    "    img = remove_background_on_left_side(img)\n",
    "    \n",
    "    # wraca do oryginalnej postaci\n",
    "    img = img.T\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Główna funkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fragment_with_text(img, img_org):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    img: Na wejście dostaje obraz binarny, gdzie wykryte tekst jest wskazywany przez 1, a reszta to 0.\n",
    "    img_org: Oryginalny niezmieniony obraz.\n",
    "    \n",
    "    Returns:\n",
    "    img_removed_background: Zwraca wycinek obrazu zawierający tekst w skali szarości z rozciągniętym histogramem.\n",
    "    img_org: Przekazuje obraz oryginalny dalej.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Szukamy regionów. Więkoszość z nich powinna znajdować się w obszarze tekstu.\n",
    "    label_img = measure.label(img)\n",
    "    regions = measure.regionprops(label_img)\n",
    "    regions_centroids = np.array([reg.centroid for reg in regions])\n",
    "    mean_centroid = (np.mean(regions_centroids[:, 0]), np.mean(regions_centroids[:, 1]))\n",
    "\n",
    "    # Usuwamy obszary, który centoridy zbyt mocno odstają. Dwukrotnie.\n",
    "    data = remove_outliers_centroids(regions_centroids, quantile_height=0.95, quantile_width=0.9)\n",
    "    data = remove_outliers_centroids(data, quantile_height=0.95, quantile_width=0.95)\n",
    "\n",
    "    # Z pozostałych centoridów tworzymy prostokąt troche powiększony.\n",
    "    height_min = np.min(data[:, 0])\n",
    "    width_min = np.min(data[:, 1])\n",
    "    height_max = np.max(data[:, 0])\n",
    "    width_max = np.max(data[:, 1])\n",
    "    \n",
    "    img_height, img_width = img.shape\n",
    "    \n",
    "    start_point_height = int(max(height_min-img_height*0.09, 1))\n",
    "    start_point_width = int(max(width_min-img_width*0.15, 1))\n",
    "    end_point_height = int(height_max+img_height*0.1)\n",
    "    end_point_width = int(width_max+img_width*0.25)\n",
    "    \n",
    "    # Wycięcie tego prostokątu z oryginalnego obrazu.\n",
    "#     img_org_path = Path('../data/ocr1') / str(image_path.stem + \".jpg\")\n",
    "#     img_org = io.imread(img_org_path)\n",
    "    img_slice = img_org[start_point_height:end_point_height, start_point_width:end_point_width]\n",
    "    \n",
    "    # Na wycinkach nadal czasami pojawia się stół. Więc usuwamy te fragmenty.\n",
    "    p2, p98 = np.percentile(img_slice, (2, 98))\n",
    "    img_slice = exposure.rescale_intensity(img_slice, in_range=(p2, p98))\n",
    "    img_removed_background = remove_background(img_slice)\n",
    "    \n",
    "    reference_point_to_img_org = (start_point_height, start_point_width)\n",
    "    return img_removed_background, img_org, reference_point_to_img_org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Adam - wykrywanie tekstu teraz z fragmentu obrazu zawierajęcego tekst.\n",
    "<p><b>Dostaniesz:</b><p>\n",
    "    - img_removed_background: obraz w skali szarości z rozciągniętym histogramem będący fragmentem oryginalnego obrazu zawierającym obszar tekstu.<p>\n",
    "    - img_org: Oryginalny niezmieniony obraz.<p>\n",
    "    - reference_point_to_img_org: Punkt odniesienia wycinku (img) do obrazu oryginalnego (img_org).<p>\n",
    "<p><b>Potrzebuję dalej:</b><p>\n",
    "    - img: Obraz binarny, gdzie wykryty tekst jest wskazywany przez 1, a reszta to 0.<p>\n",
    "    - img_org: Oryginalny niezmieniony obraz.<p>\n",
    "    - reference_point_to_img_org: Punkt odniesienia wycinku (img) do obrazu oryginalnego (img_org).<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Wykrywanie obszarów słów w obrazie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines_of_text(img):    \n",
    "    # obliczamy średnią jasność wierszy w obrazie\n",
    "    sum_of_rows = np.sum(img, axis=1) \n",
    "    mean_row_value = np.mean(sum_of_rows)\n",
    "    \n",
    "    # wiersze poniżej średniej jasności zerujemy (usuwa np. ogonki liter nachodzących na kolejne wiersze)\n",
    "    # chodzi o to żeby wyciągnąć na pewno te wiersze obrazu, w których jest tekst\n",
    "    for i, row in enumerate(img):\n",
    "        if np.sum(row) < mean_row_value: # mean_row_value, ale to jest takie niefajne, eh\n",
    "            row = np.zeros(row.shape)\n",
    "            img[i] = row\n",
    "        \n",
    "    # zaznaczamy obszary, które są powyżej średniej (całe wiersze)\n",
    "    for i, row in enumerate(img):\n",
    "        if np.sum(row) > 0.0:\n",
    "            img[i:i+1, :] = 1 \n",
    "            \n",
    "    # łączenie lekko rozdzielonych linijek\n",
    "#     img = morphology.dilation(img, morphology.disk(5)) # TODO WAŻNE - zoptymalizować!\n",
    "                \n",
    "    return img\n",
    "            \n",
    "\n",
    "def detect_words_in_line(image_result, image_binary, coords_of_line, row_intensity=255):\n",
    "    # wycinamy kawałek obrazu będącego linią tekstu i obracamy go (.T)\n",
    "    line_img = get_slice_of_image_with_specific_coords(image=image_binary, coords=coords_of_line).T\n",
    "    line_img = morphology.dilation(line_img, morphology.disk(13))\n",
    "    \n",
    "    # szukamy miejsc, w których jasność jest większa od 0.0 i te miejsca zaznaczamy w wycinku obrazu\n",
    "    # (obraz jest obrócony, więc tekst idzie z góry na dół)\n",
    "    sum_of_rows = np.sum(line_img, axis=1) \n",
    "    mean_row_value = np.mean(sum_of_rows)\n",
    "    for i, row in enumerate(line_img):\n",
    "        if np.mean(row) > 0.0:\n",
    "#             line_img[i:i+1, :] = (255, 0, 0)\n",
    "            line_img[i:i+1, :] = row_intensity\n",
    "    # znowu obracamy, tekst biegnie od lewej do prawej\n",
    "    line_img = line_img.T\n",
    "    \n",
    "    # wykrywamy regiony, czyli pojedynczy region to powinien być jeden wyraz\n",
    "    label_line_img = measure.label(line_img)\n",
    "    regions = measure.regionprops(label_line_img)\n",
    "#     print(\"liczba słów: \", len(regions))\n",
    "    \n",
    "    # tutaj szukamy regionu, który jest najdalej na lewo - czyli indeksu\n",
    "    max_width_coord = max(regions[0].coords[:, 1])\n",
    "    max_region_index = 0\n",
    "    for i, region in enumerate(regions[1:]):        \n",
    "        temp = max(region.coords[:, 1])\n",
    "        if temp > max_width_coord:\n",
    "            max_width_coord = temp\n",
    "            max_region_index = i + 1\n",
    "    \n",
    "    # czyli mamy wszystkie współrzędne regionu z indeksem\n",
    "    last_word_coords = regions[max_region_index].coords\n",
    "    # ale aktualnie do tego regionu odnosimy się względem naszego wycinka obrazu - jednego wiersza\n",
    "    # a chcemy go zaznaczyć na całym obrazie, więc do współrzędnych dodajemy współrzędne naszego wycinka,\n",
    "    # (te współrzędne wycinka odnoszą się do całego obrazu)\n",
    "    last_word_coords[:,0] += coords_of_line[0][0]\n",
    "    \n",
    "    # zamieniamy ten wycinek obrazu w całym obrazie\n",
    "    first_point = coords_of_line[0]\n",
    "    last_point = coords_of_line[-1]\n",
    "    image_result[first_point[0]:last_point[0]+1, first_point[1]:last_point[1]+1] = line_img\n",
    "                \n",
    "    return last_word_coords\n",
    "\n",
    "\n",
    "def get_slice_of_image_with_specific_coords(image, coords):\n",
    "    height = coords[:, 0]\n",
    "    width = coords[:, 1]\n",
    "    slice_image = image[(height, width)].reshape((-1, image.shape[1]))\n",
    "    \n",
    "    return slice_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Główna funkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_k_wyrazy = Path('../data/partial_results/k_wyrazy_2') # POTRZEBNE - to jeden z wyników zadania\n",
    "save_path_k_wyrazy.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def detect_fragments_with_words(img, img_org, reference_point_to_img_org):\n",
    "    \"\"\"\n",
    "    Zapisuje k-wyrazy.png oraz wykrywa fragmenty obrazu reprezentującego indeksy.\n",
    "    \n",
    "    Parameters:\n",
    "    img: Na wejście dostaje obraz binarny, gdzie wykryty tekst jest wskazywany przez 1, a reszta to 0.\n",
    "    img_org: Oryginalny niezmieniony obraz.\n",
    "    reference_point_to_img_org: Punkt odniesienia wycinku (img) do obrazu oryginalnego (img_org).\n",
    "    \n",
    "    Returns:\n",
    "    last_word_images: Lista wyciętych fragmentów indeksów z oryginalnego obrazu.\n",
    "    \n",
    "    \"\"\"    \n",
    "    img_detected_rows = detect_lines_of_text(img.copy()) \n",
    "     \n",
    "    # region = linia tekstu\n",
    "    label_image = measure.label(img_detected_rows)\n",
    "    regions = measure.regionprops(label_image)\n",
    "    \n",
    "#     width = img_canny.shape[1]\n",
    "#     regions = [reg for reg in regions if reg.area > width*5] # wiersze powyżej 7 pikseli wysokości\n",
    "#     print(\"regions po usunięciu cienkich wierszy: \", len(regions))\n",
    "    \n",
    "    # Wynikowy obraz ma mieć czarne tło, a wyrazy w kolejnych wierszach mają mieć wartości 1,2,3...\n",
    "    image_result = np.zeros(img.shape, dtype=np.uint8)\n",
    "    last_words = []\n",
    "    for i, region in enumerate(regions, 1):\n",
    "        last_word_coords = detect_words_in_line(image_result=image_result, \n",
    "                                               image_binary=img, \n",
    "                                               coords_of_line=region.coords, \n",
    "                                               row_intensity=((i*1)%256))\n",
    "        \n",
    "        last_word_coords_height = last_word_coords[0] + reference_point_to_img_org[0]\n",
    "        last_word_coords_width = last_word_coords[1] + reference_point_to_img_org[1]\n",
    "        last_words.append([last_word_coords_height, last_word_coords_width])\n",
    "    \n",
    "    # Zapisywanie k-wyrazy        \n",
    "    io.imsave(arr=image_result, fname=save_path_k_wyrazy / '{}-wyrazy.png'.format(number_of_image))\n",
    "\n",
    "    \n",
    "    # Utworzenie katalogu dla wycinka indeksu.\n",
    "#     number_of_image = re.search('[0-9]+', image_path.stem)[0]\n",
    "#     last_word_directory = save_path / number_of_image\n",
    "#     last_word_directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Wycięcie indeksu (last_word) z oryginalnego obrazu i dodanie go do listy wszystkich.\n",
    "    last_word_images = []\n",
    "    for i, last_word_coords in enumerate(last_words):\n",
    "        first_point = last_word_coords[0]\n",
    "        last_point = last_word_coords[-1]\n",
    "        last_word_img = img_org[first_point[0]:last_point[0]+1, first_point[1]:last_point[1]+1] \n",
    "        last_word_images.append(last_word_img)\n",
    "        # Zapisanie\n",
    "#         io.imsave(arr=last_word_img, fname=last_word_directory / '{}.png'.format(i))\n",
    "\n",
    "    return last_word_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Wycięcie cyfr z obrazów indeksów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage import filters\n",
    "from skimage import transform\n",
    "from skimage import measure\n",
    "from skimage import exposure\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rect_points - (start_point, end_point), where p0 is top-left corner, p1 is down-right corner\n",
    "def euclidean_distance(p1, p2):\n",
    "        return pow(pow(p1[0]-p2[0],2)+pow(p1[1]-p2[1],2),0.5)\n",
    "\n",
    "\n",
    "def sort_regions_by_area(regions, descending=True):     \n",
    "    def func(region):\n",
    "        return region.area\n",
    "\n",
    "    regions = sorted(regions, key=func, reverse=descending)\n",
    "    return regions\n",
    "\n",
    "def get_binary_image_with_digits(word_image):\n",
    "    # Multio-Otsu dzieli obraz na 3 klasy o różnych jasnościach.\n",
    "    thresholds = filters.threshold_multiotsu(word_image, classes=3)\n",
    "\n",
    "    # Regions - to obraz, który ma wartości od 0 do 2. \n",
    "    # Wartość odpowiada regionowi, do którego należey dany piksel.\n",
    "    otsu_regions = np.digitize(word_image, bins=thresholds)\n",
    "\n",
    "    # Jeden z wykrytych regionów odpowiadał w większości jasności kratki, więc go usuwam.\n",
    "    # Region trzeba traktować jako jakiś przedział wartości jasności w obrazie.\n",
    "    image_removed_otsu_region = word_image*util.invert((otsu_regions == 1))\n",
    "\n",
    "    # Po ponownym wykryciu regionów, jeden z nich pasował do cyfr więc użyłem go licząc, że są to cyfry.\n",
    "    thresholds = filters.threshold_multiotsu(image_removed_otsu_region, classes=3)\n",
    "    otsu_regions = np.digitize(word_image, bins=thresholds)\n",
    "    image_digits = (otsu_regions==0)\n",
    "    \n",
    "    return image_digits\n",
    "\n",
    "def get_digits_regions(image_digits):\n",
    "    # Tutaj region to już chodzi o podobne jasności pikseli w sąsiedztwie.\n",
    "    label_image = measure.label(image_digits)\n",
    "    regions = measure.regionprops(label_image)\n",
    "    \n",
    "    # usuwanie regionów, które są zbyt szerokie na liczbę (usuwa wykryte poziome linie kratki)\n",
    "    # źle działa dla 2_1, cyfra 5 jest zbyt duża\n",
    "#     width = image_digits.shape[1] \n",
    "#     regions_width = [(np.max(reg.coords[:, 1]) - np.min(reg.coords[:, 1])) for reg in regions]\n",
    "#     regions = [reg for i, reg in enumerate(regions) if regions_width[i] < width/5]\n",
    "\n",
    "#     print(\"liczba wykrytych regionów (cyfr): \", len(regions))\n",
    "    \n",
    "    \n",
    "    return regions\n",
    "\n",
    "\n",
    "def remove_overlapped_regions(regions_as_rect_points):\n",
    "    # usunięcie regionów zbytnio nakładajacych się na siebie, prawdopodobnie cyfra została podzielona na górę-dół\n",
    "    \n",
    "    regions_list_with_key = []\n",
    "    for i, reg in enumerate(regions_as_rect_points):\n",
    "        regions_list_with_key.append([i, reg])\n",
    "    \n",
    "    valid_regions = []\n",
    "    invalid_regions_keys = []\n",
    "    l1 = regions_list_with_key[0:]\n",
    "    l2 = regions_list_with_key[1:]\n",
    "    for reg1_dict, reg2_dict in zip(l1, l2): \n",
    "        reg1_key, reg1 = reg1_dict\n",
    "        reg2_key, reg2 = reg2_dict\n",
    "        \n",
    "        if reg1_key in invalid_regions_keys:\n",
    "            continue\n",
    "\n",
    "        reg1_start_point, reg1_end_point = reg1\n",
    "        reg2_start_point, reg2_end_point = reg2\n",
    "        \n",
    "        diff = reg2_start_point[1] - reg1_end_point[1] \n",
    "        if diff < 0: # jeżeli regiony oddalone o mniej niż 'diff' pikseli to połącz w jeden\n",
    "            new_start_point, new_end_point = combine_two_overlapping_regions(reg1, reg2)\n",
    "                \n",
    "            valid_regions.append([new_start_point, new_end_point])              \n",
    "            invalid_regions_keys.append(reg1_key)\n",
    "            invalid_regions_keys.append(reg2_key)\n",
    "\n",
    "    \n",
    "    for key, reg in regions_list_with_key:\n",
    "        if key not in invalid_regions_keys:\n",
    "            valid_regions.append(reg)\n",
    "            \n",
    "    return valid_regions\n",
    "\n",
    "def combine_two_overlapping_regions(reg1, reg2):\n",
    "    reg1_start_point, reg1_end_point = reg1\n",
    "    reg2_start_point, reg2_end_point = reg2\n",
    "        \n",
    "    new_start_point = []\n",
    "    new_end_point = []\n",
    "\n",
    "    if reg1_start_point[0] < reg2_start_point[0]:\n",
    "        new_start_point.append(reg1_start_point[0])\n",
    "    else:\n",
    "        new_start_point.append(reg2_start_point[0])\n",
    "    if reg1_start_point[1] < reg2_start_point[1]:\n",
    "        new_start_point.append(reg1_start_point[1])\n",
    "    else:\n",
    "        new_start_point.append(reg2_start_point[1])           \n",
    "\n",
    "    if reg1_end_point[0] > reg2_end_point[0]:\n",
    "        new_end_point.append(reg1_end_point[0])\n",
    "    else:\n",
    "        new_end_point.append(reg2_end_point[0])\n",
    "    if reg1_end_point[1] > reg2_end_point[1]:\n",
    "        new_end_point.append(reg1_end_point[1])\n",
    "    else:\n",
    "        new_end_point.append(reg2_end_point[1])\n",
    "        \n",
    "    return new_start_point, new_end_point\n",
    "\n",
    "def get_list_of_rectangle_points(regions):\n",
    "    rect_points = [get_two_points_to_create_rectangle_from_region(reg) for reg in regions]\n",
    "    \n",
    "    # usuwanie bardzo małych wykrytych obszarów\n",
    "    def func_area(points):\n",
    "        start_point, end_point = points\n",
    "        width = abs(end_point[1]-start_point[1])\n",
    "        height = abs(end_point[0]-start_point[0])\n",
    "        return width*height\n",
    "    \n",
    "    rect_points_area = [func_area(reg) for reg in rect_points]\n",
    "    rect_points = [reg for i, reg in enumerate(rect_points) if rect_points_area[i] > 20]\n",
    "    \n",
    "    # sortowanie obszarów, biegnących od lewej do prawej - aby cyfry były po kolei\n",
    "    def func(points):\n",
    "        p0, p1 = points\n",
    "        return (p0[1] + p1[1])/2   \n",
    "    rect_points_sorted_by_distance_to_start_of_horizontal_axis = sorted(rect_points, key=func)    \n",
    "    rect_points = remove_overlapped_regions(rect_points_sorted_by_distance_to_start_of_horizontal_axis)\n",
    "    rect_points = sorted(rect_points, key=func) \n",
    "    rect_points = remove_overlapped_regions(rect_points)\n",
    "    rect_points = sorted(rect_points, key=func) \n",
    "    \n",
    "#     rect_points = rect_points_sorted_by_distance_to_start_of_horizontal_axis # TODO do usunięcia\n",
    "\n",
    "#     l1 = rect_points[0:]\n",
    "#     l2 = rect_points[1:]\n",
    "#     for reg1, reg2 in zip(l1, l2):\n",
    "#         half_diff = int((reg2[0][1] - reg1[1][1])/2)\n",
    "#         reg1[1][1] += half_diff\n",
    "#         reg2[0][1] -= half_diff\n",
    "        \n",
    "#     print(\"liczba wykrytych regionów ostatecznie (cyfr): \", len(rect_points))\n",
    "#     print(rect_points)\n",
    "    return rect_points\n",
    "        \n",
    "\n",
    "def get_two_points_to_create_rectangle_from_region(region):\n",
    "    height_min = np.min(region.coords[:, 0])\n",
    "    width_min = np.min(region.coords[:, 1])\n",
    "    height_max = np.max(region.coords[:, 0])\n",
    "    width_max = np.max(region.coords[:, 1])\n",
    "    \n",
    "    return [[height_min, width_min], [height_max, width_max]]\n",
    "\n",
    "def scale_digit_image(image, scale=28):\n",
    "    (h, w) = image.shape\n",
    "    \n",
    "    if abs(h-w) < 2:\n",
    "        image = transform.resize(image, (scale,scale))\n",
    "        return image\n",
    "    if h > w: \n",
    "        half_diff = int((h-w)/2) # zakładamy, że jednak zawsze cyfra jest wyższa niż szersza\n",
    "        \n",
    "        # left border\n",
    "        new_image_left_border = np.full((h,w+half_diff), fill_value=0, dtype=np.uint8)\n",
    "        new_image_left_border[:,half_diff:] = image\n",
    "        image = new_image_left_border\n",
    "              \n",
    "        # right border\n",
    "        fill_value = (h-w) - 2*half_diff\n",
    "        (h, w) = image.shape\n",
    "        new_image_right_border = np.full((h,w+half_diff+fill_value), fill_value=0, dtype=np.uint8)\n",
    "        new_image_right_border[:,:-half_diff-fill_value] = image\n",
    "        image = new_image_right_border\n",
    "        \n",
    "    else:\n",
    "        half_diff = int((w-h)/2) # zakładamy, że jednak zawsze cyfra jest wyższa niż szersza\n",
    "\n",
    "        # bottom border  \n",
    "        new_image_bot_border = np.full((h+half_diff,w), fill_value=0, dtype=np.uint8)\n",
    "        new_image_bot_border[:-half_diff,:] = image\n",
    "        image = new_image_bot_border\n",
    "\n",
    "        # top border\n",
    "        fill_value = (w-h) - 2*half_diff\n",
    "        (h, w) = image.shape\n",
    "        new_image_top_border = np.full((h+half_diff+fill_value,w), fill_value=0, dtype=np.uint8)\n",
    "        new_image_top_border[half_diff+fill_value:,:] = image\n",
    "        image = new_image_top_border\n",
    "    \n",
    "    image = transform.resize(image, (scale,scale)) # to zmienia na float8\n",
    "    image = util.img_as_bool(image) # jak tego nie użyłem to po zmianie na uint8 (czyli akcja niżej) \n",
    "                                    # miałem wartości inne niż 0 i 255 (np. 254)\n",
    "    image = util.img_as_ubyte(image) # nie mogę zapisywać obrazów typu bool, czyli takich jak wyżej, więc zmiana na uint8\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Główna funkcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_digits_from_index_image(last_word_images):\n",
    "    \"\"\"\n",
    "    Wycina cyfry z obrazu indeksu i zapisuje wykryte indeksy do k-indeksy.txt.\n",
    "    \n",
    "    Parameters:\n",
    "    last_word_images: List obrazów indeksów.\n",
    "    \n",
    "    \"\"\"   \n",
    "        \n",
    "    for word_image_org in last_word_images:\n",
    "        # Wczytanie obrazu\n",
    "        word_image = word_image_org.copy()\n",
    "        word_image = color.rgb2gray(word_image)\n",
    "        word_image = filters.gaussian(word_image)\n",
    "\n",
    "        # Rozciąganie jasności obrazu.\n",
    "        p2, p98 = np.percentile(word_image, (2, 98))\n",
    "        word_image = exposure.rescale_intensity(word_image, in_range=(p2, p98))\n",
    "\n",
    "        image_digits = get_binary_image_with_digits(word_image)\n",
    "\n",
    "        regions = get_digits_regions(image_digits)    \n",
    "        rect_points_sorted_by_distance_to_start_of_horizontal_axis = get_list_of_rectangle_points(regions)\n",
    "\n",
    "        word_image = color.gray2rgb(word_image)  \n",
    "        image_digits = util.img_as_ubyte(image_digits)\n",
    "        temp_image = word_image_org.copy()\n",
    "        for index_digit, (start_point, end_point) in enumerate(rect_points_sorted_by_distance_to_start_of_horizontal_axis):           \n",
    "            # Narysowanie prostokąta wokół cyfry.\n",
    "#             rr, cc = draw.rectangle_perimeter(start_point, end_point, shape=word_image_org.shape)         \n",
    "#             temp_image[rr, cc] = (255,0+index_digit*30,0+index_digit*30)\n",
    "\n",
    "            # Wycięcie cyfry\n",
    "            one_digit =  image_digits[:, start_point[1]:end_point[1]+1]\n",
    "            one_digit = scale_digit_image(one_digit, scale=28)\n",
    "            # TUTAJ MAMY OBRAZ JEDNEJ CYFRY, więc trzeba użyć sieci do wykrycia\n",
    "            # a po pętli zapisać całą liczbę do pliku tekstowego?\n",
    "            \n",
    "#             io.imsave(arr=one_digit, fname=word_directory / '{}.png'.format(index_digit))\n",
    "\n",
    "#         io.imsave(arr=temp_image, fname=word_directory / 'index.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
