{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aktualne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines_of_text(img):    \n",
    "    # obliczamy średnią jasność wierszy w obrazie\n",
    "    sum_of_rows = np.sum(img, axis=1) \n",
    "    mean_row_value = np.mean(sum_of_rows)\n",
    "    \n",
    "    # wiersze poniżej średniej jasności zerujemy (usuwa np. ogonki liter nachodzących na kolejne wiersze)\n",
    "    # chodzi o to żeby wyciągnąć na pewno te wiersze obrazu, w których jest tekst\n",
    "    for i, row in enumerate(img):\n",
    "#         print(np.sum(row))\n",
    "        if np.sum(row) < 5000: # lub mean_row_value, ale to jest takie niefajne, eh\n",
    "            row = np.zeros(row.shape)\n",
    "            img[i] = row\n",
    "        \n",
    "    # zaznaczamy obszary, które są powyżej średniej (całe wiersze)\n",
    "    for i, row in enumerate(img):\n",
    "#         print(np.mean(row))\n",
    "        if np.sum(row) > 0.0:\n",
    "            img[i:i+1, :] = 1 \n",
    "            \n",
    "    # łączenie lekko rozdzielonych linijek\n",
    "#     img = morphology.dilation(img, morphology.disk(7)) # TODO WAŻNE - zoptymalizować!\n",
    "                \n",
    "    return img\n",
    "            \n",
    "\n",
    "def detect_words_in_line(image_result, image_binary, coords_of_line, row_intensity=255):\n",
    "    # wycinamy kawałek obrazu będącego linią tekstu i obracamy go (.T)\n",
    "    line_img = get_slice_of_image_with_specific_coords(image=image_binary, coords=coords_of_line).T\n",
    "    line_img = morphology.dilation(line_img, morphology.disk(17))\n",
    "    \n",
    "    # szukamy miejsc, w których jasność jest większa od 0.0 i te miejsca zaznaczamy w wycinku obrazu\n",
    "    # (obraz jest obrócony, więc tekst idzie z góry na dół)\n",
    "    sum_of_rows = np.sum(line_img, axis=1) \n",
    "    mean_row_value = np.mean(sum_of_rows)\n",
    "    for i, row in enumerate(line_img):\n",
    "        if np.mean(row) > 0.0:\n",
    "#             line_img[i:i+1, :] = (255, 0, 0)\n",
    "            line_img[i:i+1, :] = row_intensity\n",
    "    # znowu obracamy, tekst biegnie od lewej do prawej\n",
    "    line_img = line_img.T\n",
    "    \n",
    "    # wykrywamy regiony, czyli pojedynczy region to powinien być jeden wyraz\n",
    "    label_line_img = measure.label(line_img)\n",
    "    regions = measure.regionprops(label_line_img)\n",
    "#     print(\"liczba słów: \", len(regions))\n",
    "    \n",
    "    # tutaj szukamy regionu, który jest najdalej na lewo - czyli indeksu\n",
    "    max_width_coord = max(regions[0].coords[:, 1])\n",
    "    max_region_index = 0\n",
    "    for i, region in enumerate(regions[1:]):        \n",
    "        temp = max(region.coords[:, 1])\n",
    "        if temp > max_width_coord:\n",
    "            max_width_coord = temp\n",
    "            max_region_index = i + 1\n",
    "    \n",
    "    # czyli mamy wszystkie współrzędne regionu z indeksem\n",
    "    last_word_coords = regions[max_region_index].coords\n",
    "    # ale aktualnie do tego regionu odnosimy się względem naszego wycinka obrazu - jednego wiersza\n",
    "    # a chcemy go zaznaczyć na całym obrazie, więc do współrzędnych dodajemy współrzędne naszego wycinka,\n",
    "    # (te współrzędne wycinka odnoszą się do całego obrazu)\n",
    "    last_word_coords[:,0] += coords_of_line[0][0]\n",
    "    \n",
    "    # zamieniamy ten wycinek obrazu w całym obrazie\n",
    "    first_point = coords_of_line[0]\n",
    "    last_point = coords_of_line[-1]\n",
    "    image_result[first_point[0]:last_point[0]+1, first_point[1]:last_point[1]+1] = line_img\n",
    "                \n",
    "    return last_word_coords\n",
    "\n",
    "\n",
    "def get_slice_of_image_with_specific_coords(image, coords):\n",
    "    height = coords[:, 0]\n",
    "    width = coords[:, 1]\n",
    "    slice_image = image[(height, width)].reshape((-1, image.shape[1]))\n",
    "    \n",
    "    return slice_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Główny program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\partial_results\\canny_adam\\img_10.png\n",
      "regions:  13\n",
      "regions po usunięciu cienkich wierszy:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-145-8a0928fed38f>:46: UserWarning: ..\\data\\partial_results\\k_wyrazy\\10-wyrazy.png is a low contrast image\n",
      "  io.imsave(arr=image_result, fname=save_path_k_wyrazy / '{}-wyrazy.png'.format(number_of_image))\n"
     ]
    }
   ],
   "source": [
    "source_path_org = Path('../data/ocr1')\n",
    "source_path_canny = Path('../data/partial_results/canny_adam')\n",
    "\n",
    "save_path = Path('../data/partial_results/wyciete_indeksy')\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_path_k_wyrazy = Path('../data/partial_results/k_wyrazy')\n",
    "save_path_k_wyrazy.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "images_paths = source_path_canny.glob(\"*.png\")\n",
    "all_k_wyrazy = []\n",
    "for image_path in images_paths:\n",
    "    image_path = Path(\"../data/partial_results/canny_adam/img_10.png\")\n",
    "    number_of_image = re.search('[0-9]+', image_path.stem)[0]\n",
    "    print(image_path)\n",
    "    img_canny = io.imread(image_path)\n",
    "    img_canny = color.rgb2gray(img_canny)\n",
    "    img_canny = morphology.closing(img_canny, morphology.disk(1))\n",
    "    img_canny = morphology.opening(img_canny, morphology.disk(1))\n",
    "  \n",
    "    img_detected_rows = detect_lines_of_text(img_canny.copy()) \n",
    "    \n",
    "#     io.imshow(img_detected_rows)\n",
    "#     break\n",
    "    \n",
    "    # region = linia tekstu\n",
    "    label_image = measure.label(img_detected_rows)\n",
    "    regions = measure.regionprops(label_image)\n",
    "    print(\"regions: \", len(regions))\n",
    "    \n",
    "#     width = img_canny.shape[1]\n",
    "#     regions = [reg for reg in regions if reg.area > width*5] # wiersze powyżej 7 pikseli wysokości\n",
    "#     print(\"regions po usunięciu cienkich wierszy: \", len(regions))\n",
    "    \n",
    "    \n",
    "    image_result = np.zeros(img_canny.shape, dtype=np.uint8)\n",
    "    last_words = []\n",
    "    for i, region in enumerate(regions, 1):\n",
    "        last_word_coords = detect_words_in_line(image_result=image_result, \n",
    "                                                           image_binary=img_canny, \n",
    "                                                           coords_of_line=region.coords, \n",
    "                                                           row_intensity=((i*1)%256))\n",
    "        last_words.append(last_word_coords)\n",
    "    \n",
    "    # zapisywanie k-wyrazy        \n",
    "    io.imsave(arr=image_result, fname=save_path_k_wyrazy / '{}-wyrazy.png'.format(number_of_image))\n",
    "    all_k_wyrazy.append(image_result)\n",
    "    \n",
    "#     io.imshow(image_result)\n",
    "#     break\n",
    "\n",
    "    # Wczytanie oryginalnego obrazu i utworzenie katalogu dla wycinka indeksu.\n",
    "    img_org = io.imread(source_path_org / (image_path.stem + \".jpg\"))\n",
    "    number_of_image = re.search('[0-9]+', image_path.stem)[0]\n",
    "    last_word_directory = save_path / number_of_image\n",
    "    last_word_directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Wycięcie indeksu (last_word) z oryginalnego obrazu i zapisanie go w katalogu dla danego obrazu.\n",
    "    for i, last_word_coords in enumerate(last_words):\n",
    "        first_point = last_word_coords[0]\n",
    "        last_point = last_word_coords[-1]\n",
    "        last_word_img = img_org[first_point[0]:last_point[0]+1, first_point[1]:last_point[1]+1] \n",
    "        io.imsave(arr=last_word_img, fname=last_word_directory / '{}.png'.format(i))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     io.imshow(img_org)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHYBA:  ..\\data\\partial_results\\k_wyrazy\\0-wyrazy\n"
     ]
    }
   ],
   "source": [
    "# kliknięcie ikony HOME (z domkiem) zmienia kolejne obrazy\n",
    "source_path = Path('../data/partial_results/k_wyrazy')\n",
    "image_paths = source_path.glob(\"*.png\")\n",
    "\n",
    "all_k_wyrazy = []\n",
    "for image_path in image_paths:\n",
    "    all_k_wyrazy.append(io.imread(image_path))\n",
    "\n",
    "cnt = 0\n",
    "def callback_home_button(event):\n",
    "    ''' this function gets called if we hit the home button'''\n",
    "    global cnt, image_paths\n",
    "    cnt+=1\n",
    "    image_paths = source_path.glob(\"*.png\")\n",
    "    print(list(image_paths)[cnt])\n",
    "#     print(source_path / \"{}\".format(image_paths[cnt].name))\n",
    "    ss.set_data(all_k_wyrazy[cnt])\n",
    "    plt.draw()\n",
    "    \n",
    "fig = plt.figure()\n",
    "\n",
    "toolbar_elements = fig.canvas.toolbar.children()\n",
    "right_button = toolbar_elements[4]\n",
    "\n",
    "right_button.clicked.connect(callback_home_button)\n",
    "ss = plt.imshow(all_k_wyrazy[cnt], interpolation='nearest')\n",
    "print(\"CHYBA: \", source_path / \"{}-wyrazy\".format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jakie problemy?\n",
    "- 10, 14 - wiersze zbyt blisko sobie i łączą się w jeden oraz wykrywa jakieś szumy po bokach\n",
    "- 12, 14 - łączenie wyrazów zbyt blisko siebie\n",
    "- 17 - w ostatniej linijce rozdzielone słowo\n",
    "- 18 - gdy napisany są ukośnie to bardzo źle wychodzi, bo wiersze się łączą\n",
    "- 19 - indeksy rozdzielone, bo duża przerwa między cyframi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
